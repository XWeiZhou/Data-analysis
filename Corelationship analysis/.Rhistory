setwd("E:/R train/Git repository/testapp/GBM analysis")
library(ggplot2)
library(gbm)
mtcars<-read.csv("GBM analysis.csv",header = T)
data <- read.csv("GBM analysis.csv",header = T)
data
library(ggplot2)
library(gbm)
data <- read.csv("GBM analysis.csv",header = T)
data_for_importance <- subset(data, NO!="NA" & NH!="NA", select=c(1:6))
set.seed(15)
gbm1 <-  gbm(A ~ B + C + D + E + F,          # formula
data=data_for_importance,                       # dataset
# -1: monotone decrease,
# +1: monotone increase,
#  0: no monotone restrictions
var.monotone = c(0, 0, 0, 0, 0),    # the amount of number is equal to the selected factors
distribution="gaussian",            # other functions please see the help for other choices
n.trees = 100,
interaction.depth = 3,
bag.fraction = 0.5,
shrinkage=0.1,                      # Shrinkage or learning rate,
train.fraction = 0.5,
n.minobsinnode = 0.5,               # minimum total weight needed in each node
cv.folds = 5,                       # do 5-fold cross-validation
keep.data=TRUE,                     # keep a copy of the dataset with the object
verbose=FALSE,                      # don't print out progress
n.cores=1)                          # use only a single core (detecting #cores is
set.seed(15)
data <- read.csv("GBM analysis.csv",header = T)
data_for_importance <- subset(data, D!="NA" & E!="NA", select=c(1:6)) # selcet the data without NA
set.seed(15)
gbm1 <-  gbm(A ~ B + C + D + E + F,          # formula
data=data_for_importance,                       # dataset
# -1: monotone decrease,
# +1: monotone increase,
#  0: no monotone restrictions
var.monotone = c(0, 0, 0, 0, 0),    # the amount of number is equal to the selected factors
distribution="gaussian",            # other functions please see the help for other choices
n.trees = 100,
interaction.depth = 3,
bag.fraction = 0.5,
shrinkage=0.1,                      # Shrinkage or learning rate,
train.fraction = 0.5,
n.minobsinnode = 0.5,               # minimum total weight needed in each node
cv.folds = 5,                       # do 5-fold cross-validation
keep.data=TRUE,                     # keep a copy of the dataset with the object
verbose=FALSE,                      # don't print out progress
n.cores=1)                          # use only a single core (detecting #cores is
set.seed(15)
# check performance using 5-fold cross-validation
best.iter <- gbm.perf(gbm1, method = "test")
#print
print(best.iter)
# plot the performance # plot variable influence
summary(gbm1,n.trees=best.iter) # based on the estimated best number of trees
library(rfPermute)
data(airquality)
ozone.rfP <- rfPermute(
Ozone ~ ., data = airquality, ntree = 100,
na.action = na.omit, nrep = 50, num.cores = 1
)
# Plot the null distributions and observed values.
plotNull(ozone.rfP)
# Plot the unscaled importance distributions and highlight significant predictors
plot(rp.importance(ozone.rfP, scale = FALSE))
# ... and the scaled measures
plot(rp.importance(ozone.rfP, scale = TRUE))
set.seed(9001)
p.value <- vector()
dataf <- as.data.frame(matrix(rep(NA, 2000), nrow=100))
names(dataf) <- c(paste("V",1:19, sep=""), "y")
for(i in 1:20) {
dataf[,i] <- rnorm(20, 50, 10)
}
#plot
require (plotrix)
seg<-get.segs(dataf)
centipede.plot(seg, main= "A centipede plot",vgrid=c(10))
#adding grids to the plot
grid(nx = 10, ny = 19, col = "gray50")
#加载包
library(ggplot2)
library(gcookbook)
#读取数据
data<-read.csv("MD.csv",header = TRUE)#####读取你的数据
#绘制图形
ggplot(data, aes(x=NPKM, y=NUE))+                #设置画图的数据项
geom_point()+ #添加数据点
stat_density2d(aes(alpha=..density..),geom = "raster",contour=FALSE)       #添加密度函数
library(rfPermute)
data(airquality)
ozone.rfP <- rfPermute(
Ozone ~ ., data = airquality, ntree = 100,
na.action = na.omit, nrep = 50, num.cores = 1
)
# Plot the null distributions and observed values.
plotNull(ozone.rfP)
# Plot the unscaled importance distributions and highlight significant predictors
plot(rp.importance(ozone.rfP, scale = FALSE))
# ... and the scaled measures
plot(rp.importance(ozone.rfP, scale = TRUE))
setwd("E:/R train/Git repository/testapp/Corelationship analysis")
# load the package
library(corrplot)
#to read the data
cor_data <- read.csv("Corelationship analysis.csv",header = T)
#to calculate the relationship between  different variables
M_cor <- cor(cor_data)
# set color
col <- colorRampPalette(c("#053061","#2166AC" , "#4393C3", "#92C5DE",
"#D1E5F0", "#FFFFFF","#FDDBC7" ,"#F4A582" ,
"#D6604D","#B2182B" ,"#67001F" ))(200)
# mat : is a matrix of data
# ... : further arguments to pass to the native R cor.test function
cor.mtest <- function(mat, ...) {
mat <- as.matrix(mat)
n <- ncol(mat)
p.mat<- matrix(NA, n, n)
diag(p.mat) <- 0
for (i in 1:(n - 1)) {
for (j in (i + 1):n) {
tmp <- cor.test(mat[, i], mat[, j], ...)
p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
}
}
colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
p.mat
}
p.mat <- cor.mtest(cor_data)     # matrix of the p-value of the correlation
p <- corrplot(M_cor, type="upper", order="hclust", tl.col="black",col=col,#Text label color
p.mat = p.mat, sig.level = 0.05)   ##
